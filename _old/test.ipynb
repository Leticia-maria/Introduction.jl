{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "using CUDA\n",
    "n_atoms = 100\n",
    "atom_mass = 10.0f0u\"u\"\n",
    "boundary = CubicBoundary(2.0f0u\"nm\", 2.0f0u\"nm\", 2.0f0u\"nm\")\n",
    "temp = 100.0f0u\"K\"\n",
    "atoms = CuArray([Atom(mass=atom_mass, σ=0.3f0u\"nm\", ϵ=0.2f0u\"kJ * mol^-1\") for i in 1:n_atoms])\n",
    "coords = CuArray(place_atoms(n_atoms, boundary; min_dist=0.3u\"nm\"))\n",
    "velocities = CuArray([velocity(atom_mass, temp) for i in 1:n_atoms])\n",
    "simulator = VelocityVerlet(dt=0.002f0u\"ps\")\n",
    "\n",
    "sys = System(\n",
    "    atoms=atoms,\n",
    "    pairwise_inters=(LennardJones(),),\n",
    "    coords=coords,\n",
    "    velocities=velocities,\n",
    "    boundary=boundary,\n",
    "    loggers=(\n",
    "        temp=TemperatureLogger(typeof(1.0f0u\"K\"), 10),\n",
    "        coords=CoordinateLogger(typeof(1.0f0u\"nm\"), 10),\n",
    "    ),\n",
    ")\n",
    "\n",
    "simulate!(sys, simulator, 1_000)\n",
    "### Let us simulate a diatomic molecule\n",
    "##### If we want to define specific interactions between atoms, for example bonds, we can do this as well. Using the same definitions as the first example, let's set up the coordinates so that paired atoms are 1 Å apart.\n",
    "## 100 atoms\n",
    "## cubic\n",
    "coords = place_atoms(n_atoms ÷ 2, boundary; min_dist=0.3u\"nm\")\n",
    "for i in 1:length(coords)\n",
    "    push!(coords, coords[i] .+ [0.1, 0.0, 0.0]u\"nm\")\n",
    "end\n",
    "\n",
    "velocities = [velocity(atom_mass, temp) for i in 1:n_atoms]\n",
    "#### Now we can use the built-in interaction list and bond types to place harmonic bonds between paired atoms.\n",
    "bonds = InteractionList2Atoms(\n",
    "    collect(1:(n_atoms ÷ 2)),           # First atom indices\n",
    "    collect((1 + n_atoms ÷ 2):n_atoms), # Second atom indices\n",
    "    repeat([\"\"], n_atoms ÷ 2),          # Bond types\n",
    "    [HarmonicBond(k=300_000.0u\"kJ * mol^-1 * nm^-2\", r0=0.1u\"nm\") for i in 1:(n_atoms ÷ 2)],\n",
    ")\n",
    "\n",
    "specific_inter_lists = (bonds,)\n",
    "##### This time, we are also going to use a neighbor list to speed up the Lennard Jones calculation. We can use the built-in ```DistanceNeighborFinder```. The arguments are a 2D array of eligible interacting pairs, the number of steps between each update and the distance cutoff to be classed as a neighbor. Since the neighbor finder is run every 10 steps we should also use a cutoff for the interaction with a cutoff distance less than the neighbor list distance.\n",
    "# All pairs apart from bonded pairs are eligible for non-bonded interactions\n",
    "nb_matrix = trues(n_atoms, n_atoms)\n",
    "for i in 1:(n_atoms ÷ 2)\n",
    "    nb_matrix[i, i + (n_atoms ÷ 2)] = false\n",
    "    nb_matrix[i + (n_atoms ÷ 2), i] = false\n",
    "end\n",
    "\n",
    "neighbor_finder = DistanceNeighborFinder(\n",
    "    nb_matrix=nb_matrix,\n",
    "    n_steps=10,\n",
    "    dist_cutoff=1.5u\"nm\",\n",
    ")\n",
    "\n",
    "pairwise_inters = (LennardJones(nl_only=true, cutoff=DistanceCutoff(1.2u\"nm\")),)\n",
    "sys = System(\n",
    "    atoms=atoms,\n",
    "    pairwise_inters=pairwise_inters,\n",
    "    specific_inter_lists=specific_inter_lists,\n",
    "    coords=coords,\n",
    "    velocities=velocities,\n",
    "    boundary=boundary,\n",
    "    neighbor_finder=neighbor_finder,\n",
    "    loggers=(\n",
    "        temp=TemperatureLogger(10),\n",
    "        coords=CoordinateLogger(10),\n",
    "    ),\n",
    ")\n",
    "\n",
    "simulator = VelocityVerlet(\n",
    "    dt=0.002u\"ps\",\n",
    "    coupling=AndersenThermostat(temp, 1.0u\"ps\"),\n",
    ")\n",
    "simulate!(sys, simulator, 1_000)\n",
    "#### This time when we view the trajectory we can add lines to show the bonds.\n",
    "visualize(\n",
    "    sys.loggers.coords,\n",
    "    boundary,\n",
    "    \"sim_diatomic.mp4\";\n",
    "    connections=[(i, i + (n_atoms ÷ 2)) for i in 1:(n_atoms ÷ 2)],\n",
    ")\n",
    "### Simulating the **protein**\n",
    "\n",
    "### Simulating gravity\n",
    "##### Molly is geared primarily to molecular simulation, but can also be used to simulate other physical systems. Let's set up a gravitational simulation. This example also shows the use of Float32, a 2D simulation and no specified units.\n",
    "atoms = [Atom(mass=1.0f0), Atom(mass=1.0f0)]\n",
    "coords = [SVector(0.3f0, 0.5f0), SVector(0.7f0, 0.5f0)]\n",
    "velocities = [SVector(0.0f0, 1.0f0), SVector(0.0f0, -1.0f0)]\n",
    "pairwise_inters = (Gravity(nl_only=false, G=1.5f0),)\n",
    "simulator = VelocityVerlet(dt=0.002f0)\n",
    "boundary = RectangularBoundary(1.0f0, 1.0f0)\n",
    "\n",
    "sys = System(\n",
    "    atoms=atoms,\n",
    "    pairwise_inters=pairwise_inters,\n",
    "    coords=coords,\n",
    "    velocities=velocities,\n",
    "    boundary=boundary,\n",
    "    loggers=(coords=CoordinateLogger(Float32, 10; dims=2),),\n",
    "    force_units=NoUnits,\n",
    "    energy_units=NoUnits,\n",
    ")\n",
    "\n",
    "simulate!(sys, simulator, 2_000)\n",
    "visualize(\n",
    "    sys.loggers.coords,\n",
    "    boundary,\n",
    "    \"sim_gravity.mp4\";\n",
    "    trails=4,\n",
    "    framerate=15,\n",
    "    color=[:orange, :lightgreen],\n",
    ")\n",
    "### A **fun topic**: simulating the solar system\n",
    "using GLMakie\n",
    "using Molly\n",
    "\n",
    "# Using get_body_barycentric_posvel from Astropy\n",
    "coords = [\n",
    "    SVector(-1336052.8665050615,  294465.0896030796 ,  158690.88781384667)u\"km\",\n",
    "    SVector(-58249418.70233503 , -26940630.286818042, -8491250.752464907 )u\"km\",\n",
    "    SVector( 58624128.321813114, -81162437.2641475  , -40287143.05760552 )u\"km\",\n",
    "    SVector(-99397467.7302648  , -105119583.06486066, -45537506.29775053 )u\"km\",\n",
    "    SVector( 131714235.34070954, -144249196.60814604, -69730238.5084304  )u\"km\",\n",
    "]\n",
    "\n",
    "velocities = [\n",
    "    SVector(-303.86327859262457, -1229.6540090943934, -513.791218405548  )u\"km * d^-1\",\n",
    "    SVector( 1012486.9596885007, -3134222.279236384 , -1779128.5093088674)u\"km * d^-1\",\n",
    "    SVector( 2504563.6403826815,  1567163.5923297722,  546718.234192132  )u\"km * d^-1\",\n",
    "    SVector( 1915792.9709661514, -1542400.0057833872, -668579.962254351  )u\"km * d^-1\",\n",
    "    SVector( 1690083.43357355  ,  1393597.7855017239,  593655.0037930267 )u\"km * d^-1\",\n",
    "]\n",
    "\n",
    "body_masses = [\n",
    "    1.989e30u\"kg\",\n",
    "    0.330e24u\"kg\",\n",
    "    4.87e24u\"kg\" ,\n",
    "    5.97e24u\"kg\" ,\n",
    "    0.642e24u\"kg\",\n",
    "]\n",
    "\n",
    "boundary = CubicBoundary(1e9u\"km\", 1e9u\"km\", 1e9u\"km\")\n",
    "\n",
    "# Convert the gravitational constant to the appropriate units\n",
    "inter = Gravity(G=convert(typeof(1.0u\"km^3 * kg^-1 * d^-2\"), Unitful.G))\n",
    "\n",
    "sys = System(\n",
    "    atoms=[Atom(mass=m) for m in body_masses],\n",
    "    pairwise_inters=(inter,),\n",
    "    coords=coords .+ (SVector(5e8, 5e8, 5e8)u\"km\",),\n",
    "    velocities=velocities,\n",
    "    boundary=boundary,\n",
    "    loggers=(coords=CoordinateLogger(typeof(1.0u\"km\"), 10),),\n",
    "    force_units=u\"kg * km * d^-2\",\n",
    "    energy_units=u\"kg * km^2 * d^-2\",\n",
    ")\n",
    "\n",
    "simulator = Verlet(\n",
    "    dt=0.1u\"d\",\n",
    "    remove_CM_motion=false,\n",
    ")\n",
    "\n",
    "simulate!(sys, simulator, 3650) # 1 year\n",
    "\n",
    "visualize(\n",
    "    sys.loggers.coords,\n",
    "    boundary,\n",
    "    \"sim_planets.mp4\";\n",
    "    trails=5,\n",
    "    color=[:yellow, :grey, :orange, :blue, :red],\n",
    "    markersize=[0.25, 0.08, 0.08, 0.08, 0.08],\n",
    "    transparency=false,\n",
    ")\n",
    "\n",
    "### Julia for Machine Learning\n",
    "- Recommending packages\n",
    "![](FluxLogo.png)\n",
    "- Showing tutorials\n",
    "[Machine Learning with Julia Language](https://youtu.be/FLAjNjcwDpI)\n",
    "### Building your first model\n",
    "#### This is a simple linear regression model that attempts to recover a linear function by looking at noisy examples.\n",
    "#### Do not forget to install Flux using ```Pkg.install(\"Flux\")```\n",
    "##### First, we’ll write a function that generates our “true” data. We’ll use to use Flux to recover W_truth and b_truth by looking only at examples of the ground_truth function.\n",
    "using Flux\n",
    "\n",
    "# Define the ground truth model. We aim to recover W_truth and b_truth using\n",
    "# only examples of ground_truth()\n",
    "W_truth = [1 2 3 4 5;\n",
    "            5 4 3 2 1]\n",
    "b_truth = [-1.0; -2.0]\n",
    "ground_truth(x) = W_truth*x .+ b_truth\n",
    "#### Next, we generate our training data by passing random vectors into the ground truth function. We’ll also add Gaussian noise using randn() so that it’s not too easy for Flux to figure out the model.\n",
    "x_train = [ 5 .* rand(5) for _ in 1:10_000 ]\n",
    "y_train = [ ground_truth(x) + 0.2 .* randn(2) for x in x_train ]\n",
    "#### There are two important things to note in this example which differ from real machine learning problems:\n",
    " - ### Our variables are individual vectors, stored inside another vector. Usually, we would have a collection of N-dimensional arrays (N >= 2) as our data.\n",
    " - ### In a real learning scenario, we would not have access to our ground truth, only the training examples.\n",
    "#### Next, we define the model we want to use to learn the data. We’ll use the same form that we used for our training data:\n",
    "model(x) = W*x .+ b\n",
    "#### We need to set the parameters of the model (W and b) to some initial values. It’s fairly common to use random values, so we’ll do that:\n",
    "W = rand(2, 5)\n",
    "b = rand(2)\n",
    "#### A loss function evaluates a machine learning model’s performance. In other words, it measures how far the model is from its target prediction. Flux lets you define your own custom loss function, or you can use one of the Loss Functions that Flux provides.\n",
    "\n",
    "#### For this example, we’ll define a loss function that measures the squared distance from the predicted output to the actual output:\n",
    "function loss(x, y)\n",
    "    ŷ = model(x)\n",
    "    sum((y .- ŷ).^2)\n",
    "  end\n",
    "#### You train a machine learning model by running an optimization algorithm (optimiser) that finds the best parameters (W and b). The best parameters for a model are the ones that achieve the best score of the loss function. Flux provides Optimisers that you can use to train a model.\n",
    "\n",
    "#### For this tutorial, we’ll use a classic gradient descent optimiser with learning rate η = 0.01:\n",
    "opt = Descent(0.01)\n",
    "#### Training a model is the process of computing the gradients with respect to the parameters for each input in the data. At every step, the optimiser updates all of the parameters until it finds a good value for them. This process can be written as a loop: we iterate over the examples in x_train and y_train and update the model for each example.\n",
    "\n",
    "#### To indicate that we want all derivatives of W and b, we write ps = Flux.params(W, b). This is a convenience function that Flux provides so that we don’t have to explicitly list every gradient we want. Check out the section on Taking Gradients if you want to learn more about how this works.\n",
    "\n",
    "#### We can now execute the training procedure for our model:\n",
    "train_data = zip(x_train, y_train)\n",
    "ps = Flux.params(W, b)\n",
    "\n",
    "for (x,y) in train_data\n",
    "  gs = Flux.gradient(ps) do\n",
    "    loss(x,y)\n",
    "  end\n",
    "  Flux.Optimise.update!(opt, ps, gs)\n",
    "end\n",
    "#### Instead of writing your own loop, you can use the built-in method on Flux:\n",
    "Flux.train!(loss, Flux.params(W, b), train_data, opt)\n",
    "#### The training loop we ran modified W and b to be closer to the values used to generate the training data (W and b). We can see how well we did by printing out the difference between the learned and actual matrices.\n",
    "@show W\n",
    "@show maximum(abs, W .- W_truth)\n",
    "#### Because the data and initialization are random, your results may vary slightly, but in most cases, the largest difference between the elements of learned and actual W matrix is no more than 4%.\n",
    "### Conclusion: **Julia is a super powerful language**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
